services:
   praw-reddit:
     build:
       context: .
       dockerfile: docker/praw_reddit/dockerfile
     container_name: praw_reddit
     env_file:
       - reddit.env
     volumes:
       - ./data/reddit_out:/app/data/reddit_out 
       - ./model:/app/model
     command: ["python", "/app/praw_reddit.py"]

   praw-reddit_custom:
     build:
       context: .
       dockerfile: docker/praw_reddit/dockerfile
     container_name: praw_reddit_custom
     env_file:
       - reddit.env
     volumes:
       - ./data/reddit_out:/app/data/reddit_out 
       - ./model:/app/model
     command: ["python", "/app/praw_reddit_custom.py"]

  broker:
    image: apache/kafka:latest
    hostname: broker
    container_name: broker
    ports:
      - '9092:9092'
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT_HOST://broker:9092,PLAINTEXT://broker:19092'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'CONTROLLER://:29093,PLAINTEXT_HOST://:9092,PLAINTEXT://:19092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: '4L6g3nShT-eMCtK--X86sw'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9092"]
      interval: 10s
      timeout: 5s
      retries: 3

  topic-creator:
    image: apache/kafka:latest
    container_name: topic-creator
    command: > 
      bash -c " sleep 2 &&
      /opt/kafka/bin/kafka-topics.sh --create --topic posts_raw --bootstrap-server broker:9092 &&
      /opt/kafka/bin/kafka-topics.sh --create --topic posts_raw_custom --bootstrap-server broker:9092"
    depends_on:
      - broker

  logstash:
    image: docker.elastic.co/logstash/logstash:8.17.0
    container_name: logstash
    environment:
      XPACK_MONITORING_ENABLED: "false"
      KAFKA_BROKER: "broker:9092"
      LS_JAVA_OPTS: "-Xms500m -Xmx500m"
    depends_on:
      - broker
    volumes:
      - ./docker/logstash/logstash_base.conf:/usr/share/logstash/pipeline/logstash.conf:ro
      - ./docker/logstash/base_sincedb:/docker/logstash/base_sincedb
      - ./data/reddit_out:/data/reddit_out
    mem_limit: 1g

   logstash_custom:
     image: docker.elastic.co/logstash/logstash:8.17.0
     container_name: logstash_custom
     environment:
       XPACK_MONITORING_ENABLED: "false"
       KAFKA_BROKER: "broker:9092"
       LS_JAVA_OPTS: "-Xms500m -Xmx500m"
     depends_on:
       - broker
     volumes:
       - ./docker/logstash/logstash_custom.conf:/usr/share/logstash/pipeline/logstash.conf:ro
       - ./docker/logstash/custom_sincedb:/docker/logstash/custom_sincedb
       - ./data/reddit_out:/data/reddit_out
     mem_limit: 1g

  spark:
    build:
      context: .
      dockerfile: docker/spark/dockerfile
    container_name: spark
    env_file:
      - ./docker/spark/hf.env
    volumes:
      - ./data/spark:/app/data/spark
    ports:
      - "4040:4040"
    environment:
      - SPARK_DRIVER_MEMORY=2g
      - SPARK_EXECUTOR_MEMORY=2g
      - HF_HOME=/app/data/spark/huggingface_cache
    command: ["spark-submit", "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4,org.elasticsearch:elasticsearch-spark-30_2.12:8.17.0", "/app/spark_app.py"]
    depends_on:
      broker:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    mem_limit: 4g

   spark_custom:
     build:
       context: .
       dockerfile: docker/spark/dockerfile
     container_name: spark_custom
     env_file:
       - ./docker/spark/hf.env
     volumes:
       - ./data/spark:/app/data/spark
     ports:
       - "4041:4041"
     environment:
       - SPARK_DRIVER_MEMORY=2g
       - SPARK_EXECUTOR_MEMORY=2g
       - HF_HOME=/app/data/spark/huggingface_cache
     command: ["spark-submit", "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4,org.elasticsearch:elasticsearch-spark-30_2.12:8.17.0", "/app/spark_app_custom.py"]
     depends_on:
       broker:
         condition: service_healthy
       elasticsearch:
         condition: service_healthy
     mem_limit: 4g

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g -XX:+UseG1GC -XX:MaxGCPauseMillis=500
    ports:
      - "9200:9200"
    volumes:
      - ./data/elasticsearch:/usr/share/elasticsearch/data
    mem_limit: 2g
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 5s
    
  elastic-mapping:
    image: curlimages/curl:latest
    container_name: elastic-mapping
    depends_on:
      - elasticsearch
    command: [ "sh", "/app/init_elasticsearch.sh" ]    
    volumes:
      - ./docker/elasticsearch/:/app

  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    volumes:
      - ./data/kibana:/usr/share/kibana/data
    depends_on:
      - elasticsearch
